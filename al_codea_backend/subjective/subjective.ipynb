{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import bs4\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "load_dotenv()\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "## load the Groq API key\n",
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh Kapoor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# model_name = \"BAAI/bge-large-en\"\n",
    "# model_kwargs = {\"device\": \"cpu\"}\n",
    "# encode_kwargs = {\"normalize_embeddings\": True}\n",
    "# hf = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Just a moment...Enable JavaScript and cookies to continue', metadata={'source': 'https://www.datacamp.com/cheat-sheet/getting-started-with-python-cheat-sheet', 'content_type': 'text/html; charset=UTF-8', 'title': 'Just a moment...', 'language': 'en-US'})]\n"
     ]
    }
   ],
   "source": [
    "embeddings=OllamaEmbeddings()\n",
    "url = \"https://www.datacamp.com/cheat-sheet/getting-started-with-python-cheat-sheet\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs)\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=250) \n",
    "final_documents=text_splitter.split_documents(docs) \n",
    "vectors=FAISS.from_documents(final_documents,embeddings) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm=ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "you are a coding test platform.\n",
    "I have give you a context of python documentation. \n",
    "You need to ask questions only on python language  <context>\n",
    "{context}\n",
    "<context>\n",
    "Questions:{input}\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retriever = vectors.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "\n",
      "Without actually running the code, can you determine what the output of the following Python code will be and explain the steps that the Python interpreter takes to execute it?\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n-1)\n",
      "\n",
      "print(factorial(5))\n",
      "```\n",
      "Answer:\n",
      "\n",
      "The output of the above code will be `120`.\n",
      "\n",
      "Explanation:\n",
      "\n",
      "1. When the Python interpreter encounters the `print` statement, it will call the `factorial` function with the argument `5`.\n",
      "2. The `factorial` function checks if `n` is equal to `0`. If it is, the function returns `1`.\n",
      "3. In this case, `n` is not equal to `0`, so the function returns the product of `n` and the result of calling `factorial` recursively with the argument `n-1`.\n",
      "4. This process repeats until `n` is equal to `0`, at which point the recursion stops and the function returns `1`.\n",
      "5. The recursive calls to `factorial` unwind, and the intermediate results are multiplied together. Specifically, `5 * factorial(4)`, `4 * factorial(3)`, `3 * factorial(2)`, `2 * factorial(1)`, and `1 * factorial(0)` are computed.\n",
      "6. Since `factorial(0)` is `1`, the final result is `5 * 4 * 3 * 2 * 1`, which is `120`.\n",
      "7. The `print` statement then outputs `120` to the console.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response=retrieval_chain.invoke({\"input\":'create 1 random subjective type question on python language generate its answer also     '})\n",
    "\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh Kapoor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()\n",
    "\n",
    "## load the Groq API key\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "llm = Groq(model=\"mixtral-8x7b-32768\", api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: The answer is mostly correct, but there is a small mistake in the explanation step 4. The function does not return the product of n and the result of calling factorial recursively with the argument n-1 right away. It first checks if n-1 is equal to 0, if it is, it returns 1, otherwise, it continues the recursion.\n",
      "\n",
      "Here is the corrected answer:\n",
      "\n",
      "Question:\n",
      "\n",
      "Without actually running the code, can you determine what the output of the following Python code will be and explain the steps that the Python interpreter takes to execute it?\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n-1)\n",
      "\n",
      "print(factorial(5))\n",
      "```\n",
      "Answer:\n",
      "\n",
      "The output of the above code will be `120`.\n",
      "\n",
      "Explanation:\n",
      "\n",
      "1. When the Python interpreter encounters the `print` statement, it will call the `factorial` function with the argument `5`.\n",
      "2. The `factorial` function checks if `n` is equal to `0`. If it is, the function returns `1`.\n",
      "3. In this case, `n` is not equal to `0`, so the function returns the product of `n` and the result of calling `factorial` recursively with the argument `n-1`.\n",
      "4. The function calls itself with the argument `n-1` and checks if `n-1` is equal to `0`. If it is, it returns `1`, otherwise, it continues the recursion.\n",
      "5. This process repeats until `n` is equal to `0`, at which point the recursion stops and the function returns `1`.\n",
      "6. The recursive calls to `factorial` unwind, and the intermediate results are multiplied together. Specifically, `5 * factorial(4)`, `4 * factorial(3)`, `3 * factorial(2)`, `2 * factorial(1)`, and `1 * factorial(0)` are computed.\n",
      "7. Since `factorial(0)` is `1`, the final result is `5 * 4 * 3 * 2 * 1`, which is `120`.\n",
      "8. The `print` statement then outputs `120` to the console.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "answer=response\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"you are an intelligent ai assistant.check the answer given. If answer has some errors then make it better  \"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=f\"{answer}\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
